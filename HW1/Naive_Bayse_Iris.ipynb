{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Naive-Bayse-Iris.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "knboc9zT3-jE"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xh3PjOzD30lk"
      },
      "source": [
        "# ***Question 3***"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XEpt52ahvuen"
      },
      "source": [
        "# import\n",
        "import numpy as np\n",
        "from keras.datasets import cifar10"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dLj8b_Cs3zWu"
      },
      "source": [
        "# load data from keras\n",
        "(x_train, y_train), (x_test, y_test) = cifar10.load_data()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KV3m4ADR4VD_",
        "outputId": "a771a02a-31d1-4354-e89a-631d7ae75252"
      },
      "source": [
        "print(f'x_train : Data type : {x_train.dtype} , Rank : {x_train.ndim} , Shape : {x_train.shape}')\n",
        "print(f'y_train : Data type : {y_train.dtype} , Rank : {y_train.ndim} , Shape : {y_train.shape}')\n",
        "print(f'x_test : Data type : {x_test.dtype} , Rank : {x_test.ndim} , Shape : {x_test.shape}')\n",
        "print(f'y_test : Data type : {y_test.dtype} , Rank : {y_test.ndim} , Shape : {y_test.shape}')\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "x_train : Data type : uint8 , Rank : 4 , Shape : (50000, 32, 32, 3)\n",
            "y_train : Data type : uint8 , Rank : 2 , Shape : (50000, 1)\n",
            "x_test : Data type : uint8 , Rank : 4 , Shape : (10000, 32, 32, 3)\n",
            "y_test : Data type : uint8 , Rank : 2 , Shape : (10000, 1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sgKqFNDQJS2u"
      },
      "source": [
        "# ***Question 4***"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rqCu9WLiJr7Y"
      },
      "source": [
        "# import\n",
        "import numpy as np\n",
        "from numpy.core.fromnumeric import mean\n",
        "import pandas as pd\n",
        "import random\n"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jn8YocK7KiLZ",
        "outputId": "82933af9-0868-4472-edab-069fbfad51d1"
      },
      "source": [
        "\"\"\"\" load data \"\"\"\n",
        "str_to_int = {}\n",
        "int_to_str = {}\n",
        "\n",
        "df = pd.read_csv('/content/iris.data', header=None)\n",
        "classes = df[df.columns[-1]].unique()\n",
        "for i, c in enumerate(classes):\n",
        "    str_to_int[c] = i\n",
        "    int_to_str[i] = c\n",
        "\n",
        "for k in str_to_int.keys():\n",
        "  print(f'{k} ===> {str_to_int[k]}')\n",
        "\n",
        "df.replace(str_to_int, inplace=True)\n",
        "dataset = df.to_numpy()\n",
        "\n",
        "dataset_dict = {}\n",
        "for k in int_to_str.keys():\n",
        "    dataset_dict[k] = []\n",
        "\n",
        "for row in dataset:\n",
        "    dataset_dict[row[-1]].append(row[:-1])\n",
        "\n",
        "for k in int_to_str.keys():\n",
        "    dataset_dict[k] = np.array(dataset_dict[k])"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iris-setosa ===> 0\n",
            "Iris-versicolor ===> 1\n",
            "Iris-virginica ===> 2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kHZMrCf3K3B_",
        "outputId": "06968b26-a83e-4efe-f0b8-5c25da68ae5e"
      },
      "source": [
        "\"\"\"split train and test data 0.1 of whole data will use for\"\"\"\n",
        "\n",
        "test_rate = 0.1\n",
        "\n",
        "def split_train_test():\n",
        "    test_num = test_rate * len(df)\n",
        "    each_class_test_number = test_num / 3\n",
        "    test_dataset = {}\n",
        "    for c in int_to_str.keys():\n",
        "        len_ci = len(dataset_dict[c])\n",
        "        random_indexs = random.sample(\n",
        "            range(int(len_ci)), int(each_class_test_number))\n",
        "        test_ci = dataset_dict[c][random_indexs]\n",
        "        dataset_dict[c] = np.delete(dataset_dict[c], random_indexs, axis=0)\n",
        "        test_dataset[c] = test_ci\n",
        "    return test_dataset\n",
        "\n",
        "# compute mean of a class\n",
        "\"\"\" return type is 1-D array\"\"\"\n",
        "def compute_mean(values):\n",
        "    return values.mean(axis=0)\n",
        "\n",
        "\n",
        "# compute std of a class\n",
        "\"\"\" return type is 1-D arrray\"\"\"\n",
        "def compute_stdev(values, means):\n",
        "    population_size, _ = values.shape\n",
        "    variance = np.sum((values - means)**2, axis=0) / float(population_size-1)\n",
        "    return np.sqrt(variance)\n",
        "\n",
        "\n",
        "\"\"\" probability of each class in general \"\"\"\n",
        "def probility_class():\n",
        "    keys = int_to_str.keys()\n",
        "    total = dataset.shape[0] - test_rate * dataset.shape[0]\n",
        "    probs = []\n",
        "    for key in keys:\n",
        "        probs.append(len(dataset_dict[key]) / total)\n",
        "    return np.array(probs)\n",
        "\n",
        "\"\"\" compute gussian probability \"\"\"\n",
        "def compute_probability_per_class(class_prob, x, means, stdevs):\n",
        "    return ((1/np.sqrt(2*np.pi*stdevs**2))*np.exp(-0.5 * ((x-means)/stdevs)**2)).prod()*(class_prob)\n",
        "\n",
        "\"\"\" compute standard devation and mean and probability of each class and features\"\"\"\n",
        "def compute_class_details():\n",
        "    class_probs = probility_class()\n",
        "    class_stdevs = []\n",
        "    class_means = []\n",
        "    for cl in int_to_str.keys():\n",
        "        mean = compute_mean(np.array(dataset_dict[cl]))\n",
        "        class_means.append(mean)\n",
        "        class_stdevs.append(compute_stdev(np.array(dataset_dict[cl]), mean))\n",
        "\n",
        "    class_stdevs = np.array(class_stdevs)\n",
        "    class_means = np.array(class_means)\n",
        "    return (class_stdevs, class_means, class_probs)\n",
        "\n",
        "\n",
        "\"\"\" predict probability per each class and choose the higher one\"\"\"\n",
        "def predict(X_test, class_stdevs, class_means, class_probs):\n",
        "    best_label, best_prob = None, -1\n",
        "    for cl in int_to_str.keys():\n",
        "        prob = compute_probability_per_class(\n",
        "            class_prob=class_probs[cl], x=X_test, means=class_means[cl], stdevs=class_stdevs[cl])\n",
        "        if best_prob < prob:\n",
        "            best_prob = prob\n",
        "            best_label = cl\n",
        "    return best_label\n",
        "\n",
        "\"\"\" Gussian naive bayes\"\"\"\n",
        "def main():\n",
        "    test_dataset = split_train_test()\n",
        "    class_stdevs, class_means, class_probs = compute_class_details()\n",
        "    accuracy = []\n",
        "\n",
        "    for key in test_dataset.keys():\n",
        "        for x_test in test_dataset[key]:\n",
        "            probability = predict(x_test, class_stdevs,\n",
        "                                  class_means, class_probs)\n",
        "            accuracy.append(key == probability)\n",
        "    acc = sum(accuracy)/len(accuracy) * 100\n",
        "    \n",
        "    print(f'The accuracy is {np.round(acc, 2)}%')\n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    main()"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The accuracy is 100.0%\n"
          ]
        }
      ]
    }
  ]
}